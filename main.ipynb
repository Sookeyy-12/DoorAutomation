{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Collecting Click>=6.0 (from face_recognition)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-19.24.2-cp312-cp312-win_amd64.whl\n",
      "Collecting numpy (from face_recognition)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting Pillow (from face_recognition)\n",
      "  Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiit\\anaconda3\\envs\\doorautofix\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Installing collected packages: face-recognition-models, dlib, Pillow, numpy, Click, face_recognition\n",
      "Successfully installed Click-8.1.7 Pillow-10.2.0 dlib-19.24.2 face-recognition-models-0.3.0 face_recognition-1.3.0 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kiit\\anaconda3\\envs\\doorautofix\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install face_recognition\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/students/KRS Door automation images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save encodings to a file\n",
    "def save_encodings(encodeDict, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(encodeDict, f)\n",
    "\n",
    "# Function to load encodings from a file\n",
    "def load_encodings(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "classNames = []\n",
    "encodeDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if saved encodings file exists, if not load the encodings from file\n",
    "if os.path.exists('encodings.pickle'):\n",
    "    encodeDict = load_encodings('encodings.pickle')\n",
    "else:\n",
    "    for person_dir in os.listdir(dataset_path):\n",
    "        person_path = os.path.join(dataset_path, person_dir)\n",
    "        if os.path.isdir(person_path):\n",
    "            # Get the list of image files in the subdirectory\n",
    "            image_files = [f for f in os.listdir(person_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(person_path, img_file)\n",
    "                curImg = cv2.imread(img_path)\n",
    "                if curImg is not None:\n",
    "                    images.append(curImg)\n",
    "                    # Append the class name (person's name) to the classNames list\n",
    "                    classNames.append(person_dir)\n",
    "\n",
    "                    # Convert image to RGB (face_recognition library requires RGB format)\n",
    "                    rgb_img = cv2.cvtColor(curImg, cv2.COLOR_BGR2RGB)\n",
    "                    # Find face encodings\n",
    "                    face_encodings = face_recognition.face_encodings(rgb_img)\n",
    "                    if len(face_encodings) > 0:\n",
    "                        # If the person already exists in the dictionary, append the encoding\n",
    "                        if person_dir in encodeDict:\n",
    "                            encodeDict[person_dir].append(face_encodings[0])\n",
    "                        # Otherwise, create a new entry in the dictionary\n",
    "                        else:\n",
    "                            encodeDict[person_dir] = [face_encodings[0]]\n",
    "                    else:\n",
    "                        print(f\"No face found in the image: {img_path}\")\n",
    "                else:\n",
    "                    print(f\"Unable to read image: {img_path}\")\n",
    "\n",
    "    # Save encodings to a file\n",
    "    save_encodings(encodeDict, 'encodings.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for face matching\n",
    "face_match_threshold = 0.4\n",
    "\n",
    "# Capture images from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    faces_in_frame = face_recognition.face_locations(imgS)\n",
    "    encoded_faces = face_recognition.face_encodings(imgS, faces_in_frame)\n",
    "    for encode_face, faceloc in zip(encoded_faces, faces_in_frame):\n",
    "        matchIndex = None\n",
    "        min_distance = float('inf')\n",
    "        for className, encoding_list in encodeDict.items():\n",
    "            for encoding in encoding_list:\n",
    "                distance = face_recognition.face_distance([encoding], encode_face)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    matchIndex = className\n",
    "\n",
    "        if matchIndex is not None and min_distance <= face_match_threshold:\n",
    "            name = matchIndex.upper().lower()\n",
    "        else:\n",
    "            name = \"unknown\"\n",
    "\n",
    "        y1, x2, y2, x1 = faceloc\n",
    "        y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cv2.rectangle(img, (x1,y2-35), (x2,y2), (0,255,0), cv2.FILLED)\n",
    "        cv2.putText(img, name, (x1+6,y2-5), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Always retrain the encodings\n",
    "# mylist = os.listdir(dataset_path)\n",
    "# for cl in mylist:\n",
    "#     if cl.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#         img_path = os.path.join(dataset_path, cl)\n",
    "#         curImg = cv2.imread(img_path)\n",
    "#         if curImg is not None:\n",
    "#             images.append(curImg)\n",
    "#             className = os.path.splitext(cl)[0]\n",
    "#             classNames.append(className)\n",
    "\n",
    "#             rgb_img = cv2.cvtColor(curImg, cv2.COLOR_BGR2RGB)\n",
    "#             face_encodings = face_recognition.face_encodings(rgb_img)\n",
    "#             if len(face_encodings) > 0:\n",
    "#                 if className in encodeDict:\n",
    "#                     encodeDict[className].append(face_encodings[0])\n",
    "#                 else:\n",
    "#                     encodeDict[className] = [face_encodings[0]]\n",
    "#             else:\n",
    "#                 print(f\"No face found in the image: {cl}\")\n",
    "\n",
    "# # Save encodings to a file\n",
    "# save_encodings(encodeDict, 'encodings.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to encode faces in the images\n",
    "# def findEncodings(images):\n",
    "#     encodeList = []\n",
    "#     for img in images:\n",
    "#         # Convert image to RGB (face_recognition library requires RGB format)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         # Find face encodings\n",
    "#         face_encodings = face_recognition.face_encodings(img)\n",
    "#         if len(face_encodings) > 0:\n",
    "#             encodeList.append(face_encodings[0])\n",
    "#         else:\n",
    "#             print(\"No face found in the image\")\n",
    "#     return encodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode faces in the loaded images\n",
    "# encoded_face_train = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def markAttendance(name):\n",
    "#     with open('Attendance.csv','r+') as f:\n",
    "#         myDataList = f.readlines()\n",
    "#         nameList = []\n",
    "#         for line in myDataList:\n",
    "#             entry = line.split(',')\n",
    "#             nameList.append(entry[0])\n",
    "#         if name not in nameList:\n",
    "#             now = datetime.now()\n",
    "#             time = now.strftime('%I:%M:%S:%p')\n",
    "#             date = now.strftime('%d-%B-%Y')\n",
    "#             f.writelines(f'n{name}, {time}, {date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_elon_encodings = face_recognition.face_encodings(imgelon)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgelon =face_recognition.load_image_file('dataset\\\\genuine\\\\WIN_20240307_21_52_24_Pro.jpg')\n",
    "# imgelon = cv2.cvtColor(imgelon,cv2.COLOR_BGR2RGB)\n",
    "# #----------Finding face Location for drawing bounding boxes-------\n",
    "# face = face_recognition.face_locations(imgelon_rgb)[0]\n",
    "# copy = imgelon.copy()\n",
    "# #-------------------Drawing the Rectangle-------------------------\n",
    "# cv2.rectangle(copy, (face[3], face[0]),(face[1], face[2]), (255,0,255), 2)\n",
    "# cv2.imshow('copy', copy)\n",
    "# cv2.imshow('elon',imgelon)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgelon_bgr = face_recognition.load_image_file('dataset\\\\genuine\\\\WIN_20240307_21_52_24_Pro.jpg')\n",
    "# imgelon_rgb = cv2.cvtColor(imgelon_bgr,cv2.COLOR_BGR2RGB)\n",
    "# cv2.imshow('bgr', imgelon_bgr)\n",
    "# cv2.imshow('rgb', imgelon_rgb)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets test an image\n",
    "# test = face_recognition.load_image_file('dataset\\\\genuine\\\\aman gupta.png')\n",
    "# test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "# test_encode = face_recognition.face_encodings(test)[0]\n",
    "# print(face_recognition.compare_faces([train_elon_encodings],test_encode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attendance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
